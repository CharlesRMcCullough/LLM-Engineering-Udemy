{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a0673e-96b5-43f2-8a8b-bd033bf851b0",
   "metadata": {},
   "source": [
    "# The Big Project begins!!\n",
    "\n",
    "## The Product Pricer\n",
    "\n",
    "A model that can estimate how much something costs, from its description.\n",
    "\n",
    "## Data Curation Part 1\n",
    "\n",
    "Today we'll begin our scrubbing and curating our dataset by focusing on a subset of the data: Home Appliances.\n",
    "\n",
    "The dataset is here:  \n",
    "https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023\n",
    "\n",
    "And the folder with all the product datasets is here:  \n",
    "https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/tree/main/raw/meta_categories"
   ]
  },
  {
   "cell_type": "code",
   "id": "67cedf85-8125-4322-998e-9375fe745597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:16:36.934459Z",
     "start_time": "2024-12-12T19:16:36.437517Z"
    }
   },
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "7390a6aa-79cb-4dea-b6d7-de7e4b13e472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:16:39.016109Z",
     "start_time": "2024-12-12T19:16:39.013504Z"
    }
   },
   "source": [
    "# environment\n",
    "\n",
    "load_dotenv()\n",
    "#os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "#os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-key-if-not-using-env')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "0732274a-aa6a-44fc-aee2-40dc8a8e4451",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:16:48.310409Z",
     "start_time": "2024-12-12T19:16:48.169740Z"
    }
   },
   "source": [
    "# Log in to HuggingFace\n",
    "\n",
    "hf_token = os.environ['HF_TOKEN']\n",
    "login(hf_token, add_to_git_credential=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/charles/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "b5521526-0da9-42d7-99e3-f950fab71662",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T19:16:55.508901Z",
     "start_time": "2024-12-12T19:16:54.703613Z"
    }
   },
   "source": [
    "# One more import - the Item class\n",
    "# If you get an error that you need to agree to Meta's terms when you run this, then follow the link it provides you and follow their instructions\n",
    "# You should get approved by Meta within minutes\n",
    "# Any problems - message me or email me!\n",
    "# With thanks to student Dr John S. for pointing out that this import needs to come after signing in to HF\n",
    "\n",
    "from items import Item"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like meta-llama/Meta-Llama-3.1-8B is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/huggingface_hub/utils/_errors.py:304\u001B[0m, in \u001B[0;36mhf_raise_for_status\u001B[0;34m(response, endpoint_name)\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 304\u001B[0m     response\u001B[38;5;241m.\u001B[39mraise_for_status()\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/requests/models.py:1024\u001B[0m, in \u001B[0;36mResponse.raise_for_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1023\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http_error_msg:\n\u001B[0;32m-> 1024\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(http_error_msg, response\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[0;31mHTTPError\u001B[0m: 403 Client Error: Forbidden for url: https://huggingface.co/meta-llama/Meta-Llama-3.1-8B/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mHfHubHTTPError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/huggingface_hub/file_download.py:1751\u001B[0m, in \u001B[0;36m_get_metadata_or_catch_error\u001B[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001B[0m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     metadata \u001B[38;5;241m=\u001B[39m get_hf_file_metadata(\n\u001B[1;32m   1752\u001B[0m         url\u001B[38;5;241m=\u001B[39murl, proxies\u001B[38;5;241m=\u001B[39mproxies, timeout\u001B[38;5;241m=\u001B[39metag_timeout, headers\u001B[38;5;241m=\u001B[39mheaders, token\u001B[38;5;241m=\u001B[39mtoken\n\u001B[1;32m   1753\u001B[0m     )\n\u001B[1;32m   1754\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m EntryNotFoundError \u001B[38;5;28;01mas\u001B[39;00m http_error:\n",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/huggingface_hub/file_download.py:1673\u001B[0m, in \u001B[0;36mget_hf_file_metadata\u001B[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001B[0m\n\u001B[1;32m   1672\u001B[0m \u001B[38;5;66;03m# Retrieve metadata\u001B[39;00m\n\u001B[0;32m-> 1673\u001B[0m r \u001B[38;5;241m=\u001B[39m _request_wrapper(\n\u001B[1;32m   1674\u001B[0m     method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHEAD\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1675\u001B[0m     url\u001B[38;5;241m=\u001B[39murl,\n\u001B[1;32m   1676\u001B[0m     headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[1;32m   1677\u001B[0m     allow_redirects\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   1678\u001B[0m     follow_relative_redirects\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m   1679\u001B[0m     proxies\u001B[38;5;241m=\u001B[39mproxies,\n\u001B[1;32m   1680\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[1;32m   1681\u001B[0m )\n\u001B[1;32m   1682\u001B[0m hf_raise_for_status(r)\n",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/huggingface_hub/file_download.py:376\u001B[0m, in \u001B[0;36m_request_wrapper\u001B[0;34m(method, url, follow_relative_redirects, **params)\u001B[0m\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m follow_relative_redirects:\n\u001B[0;32m--> 376\u001B[0m     response \u001B[38;5;241m=\u001B[39m _request_wrapper(\n\u001B[1;32m    377\u001B[0m         method\u001B[38;5;241m=\u001B[39mmethod,\n\u001B[1;32m    378\u001B[0m         url\u001B[38;5;241m=\u001B[39murl,\n\u001B[1;32m    379\u001B[0m         follow_relative_redirects\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    380\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[1;32m    381\u001B[0m     )\n\u001B[1;32m    383\u001B[0m     \u001B[38;5;66;03m# If redirection, we redirect only relative paths.\u001B[39;00m\n\u001B[1;32m    384\u001B[0m     \u001B[38;5;66;03m# This is useful in case of a renamed repository.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/huggingface_hub/file_download.py:400\u001B[0m, in \u001B[0;36m_request_wrapper\u001B[0;34m(method, url, follow_relative_redirects, **params)\u001B[0m\n\u001B[1;32m    399\u001B[0m response \u001B[38;5;241m=\u001B[39m get_session()\u001B[38;5;241m.\u001B[39mrequest(method\u001B[38;5;241m=\u001B[39mmethod, url\u001B[38;5;241m=\u001B[39murl, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[0;32m--> 400\u001B[0m hf_raise_for_status(response)\n\u001B[1;32m    401\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/huggingface_hub/utils/_errors.py:367\u001B[0m, in \u001B[0;36mhf_raise_for_status\u001B[0;34m(response, endpoint_name)\u001B[0m\n\u001B[1;32m    361\u001B[0m     message \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    362\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Forbidden: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00merror_message\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    363\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mCannot access content at: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    364\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mIf you are trying to create or update content, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    365\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmake sure you have a token with the `write` role.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    366\u001B[0m     )\n\u001B[0;32m--> 367\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HfHubHTTPError(message, response\u001B[38;5;241m=\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    369\u001B[0m \u001B[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001B[39;00m\n\u001B[1;32m    370\u001B[0m \u001B[38;5;66;03m# as well (request id and/or server error message)\u001B[39;00m\n",
      "\u001B[0;31mHfHubHTTPError\u001B[0m:  (Request ID: Root=1-675b36a6-1847b3874e8432562d588a96;856bfda8-5732-44f7-8689-2bce75d6e6bc)\n\n403 Forbidden: Please enable access to public gated repositories in your fine-grained token settings to view this repository..\nCannot access content at: https://huggingface.co/meta-llama/Meta-Llama-3.1-8B/resolve/main/config.json.\nIf you are trying to create or update content, make sure you have a token with the `write` role.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mLocalEntryNotFoundError\u001B[0m                   Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/transformers/utils/hub.py:403\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    402\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[0;32m--> 403\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m hf_hub_download(\n\u001B[1;32m    404\u001B[0m         path_or_repo_id,\n\u001B[1;32m    405\u001B[0m         filename,\n\u001B[1;32m    406\u001B[0m         subfolder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(subfolder) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m subfolder,\n\u001B[1;32m    407\u001B[0m         repo_type\u001B[38;5;241m=\u001B[39mrepo_type,\n\u001B[1;32m    408\u001B[0m         revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[1;32m    409\u001B[0m         cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n\u001B[1;32m    410\u001B[0m         user_agent\u001B[38;5;241m=\u001B[39muser_agent,\n\u001B[1;32m    411\u001B[0m         force_download\u001B[38;5;241m=\u001B[39mforce_download,\n\u001B[1;32m    412\u001B[0m         proxies\u001B[38;5;241m=\u001B[39mproxies,\n\u001B[1;32m    413\u001B[0m         resume_download\u001B[38;5;241m=\u001B[39mresume_download,\n\u001B[1;32m    414\u001B[0m         token\u001B[38;5;241m=\u001B[39mtoken,\n\u001B[1;32m    415\u001B[0m         local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[1;32m    416\u001B[0m     )\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m GatedRepoError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:101\u001B[0m, in \u001B[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    100\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(message, \u001B[38;5;167;01mFutureWarning\u001B[39;00m)\n\u001B[0;32m--> 101\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/huggingface_hub/file_download.py:1240\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001B[0m\n\u001B[1;32m   1239\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _hf_hub_download_to_cache_dir(\n\u001B[1;32m   1241\u001B[0m         \u001B[38;5;66;03m# Destination\u001B[39;00m\n\u001B[1;32m   1242\u001B[0m         cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n\u001B[1;32m   1243\u001B[0m         \u001B[38;5;66;03m# File info\u001B[39;00m\n\u001B[1;32m   1244\u001B[0m         repo_id\u001B[38;5;241m=\u001B[39mrepo_id,\n\u001B[1;32m   1245\u001B[0m         filename\u001B[38;5;241m=\u001B[39mfilename,\n\u001B[1;32m   1246\u001B[0m         repo_type\u001B[38;5;241m=\u001B[39mrepo_type,\n\u001B[1;32m   1247\u001B[0m         revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[1;32m   1248\u001B[0m         \u001B[38;5;66;03m# HTTP info\u001B[39;00m\n\u001B[1;32m   1249\u001B[0m         endpoint\u001B[38;5;241m=\u001B[39mendpoint,\n\u001B[1;32m   1250\u001B[0m         etag_timeout\u001B[38;5;241m=\u001B[39metag_timeout,\n\u001B[1;32m   1251\u001B[0m         headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[1;32m   1252\u001B[0m         proxies\u001B[38;5;241m=\u001B[39mproxies,\n\u001B[1;32m   1253\u001B[0m         token\u001B[38;5;241m=\u001B[39mtoken,\n\u001B[1;32m   1254\u001B[0m         \u001B[38;5;66;03m# Additional options\u001B[39;00m\n\u001B[1;32m   1255\u001B[0m         local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[1;32m   1256\u001B[0m         force_download\u001B[38;5;241m=\u001B[39mforce_download,\n\u001B[1;32m   1257\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/huggingface_hub/file_download.py:1347\u001B[0m, in \u001B[0;36m_hf_hub_download_to_cache_dir\u001B[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001B[0m\n\u001B[1;32m   1346\u001B[0m     \u001B[38;5;66;03m# Otherwise, raise appropriate error\u001B[39;00m\n\u001B[0;32m-> 1347\u001B[0m     _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n\u001B[1;32m   1349\u001B[0m \u001B[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/huggingface_hub/file_download.py:1857\u001B[0m, in \u001B[0;36m_raise_on_head_call_error\u001B[0;34m(head_call_error, force_download, local_files_only)\u001B[0m\n\u001B[1;32m   1855\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1856\u001B[0m     \u001B[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001B[39;00m\n\u001B[0;32m-> 1857\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m LocalEntryNotFoundError(\n\u001B[1;32m   1858\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error happened while trying to locate the file on the Hub and we cannot find the requested files\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1859\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m in the local cache. Please check your connection and try again or make sure your Internet connection\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1860\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is on.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1861\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhead_call_error\u001B[39;00m\n",
      "\u001B[0;31mLocalEntryNotFoundError\u001B[0m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 7\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# One more import - the Item class\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# If you get an error that you need to agree to Meta's terms when you run this, then follow the link it provides you and follow their instructions\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# You should get approved by Meta within minutes\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Any problems - message me or email me!\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# With thanks to student Dr John S. for pointing out that this import needs to come after signing in to HF\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mitems\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Item\n",
      "File \u001B[0;32m~/Source/Repos/PythonProjects/UdemyCourses/LLM-Engineering-Udemy/Week6/items.py:13\u001B[0m\n\u001B[1;32m     10\u001B[0m MIN_CHARS \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m300\u001B[39m\n\u001B[1;32m     11\u001B[0m CEILING_CHARS \u001B[38;5;241m=\u001B[39m MAX_TOKENS \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m7\u001B[39m\n\u001B[0;32m---> 13\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mItem\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m    An Item is a cleaned, curated datapoint of a Product with a Price\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m     18\u001B[0m     tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(BASE_MODEL, trust_remote_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Source/Repos/PythonProjects/UdemyCourses/LLM-Engineering-Udemy/Week6/items.py:18\u001B[0m, in \u001B[0;36mItem\u001B[0;34m()\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mItem\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m    An Item is a cleaned, curated datapoint of a Product with a Price\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m     tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(BASE_MODEL, trust_remote_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     19\u001B[0m     PREFIX \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrice is $\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     20\u001B[0m     QUESTION \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHow much does this cost to the nearest dollar?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:864\u001B[0m, in \u001B[0;36mAutoTokenizer.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m    862\u001B[0m         config \u001B[38;5;241m=\u001B[39m AutoConfig\u001B[38;5;241m.\u001B[39mfor_model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig_dict)\n\u001B[1;32m    863\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 864\u001B[0m         config \u001B[38;5;241m=\u001B[39m AutoConfig\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[1;32m    865\u001B[0m             pretrained_model_name_or_path, trust_remote_code\u001B[38;5;241m=\u001B[39mtrust_remote_code, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    866\u001B[0m         )\n\u001B[1;32m    867\u001B[0m config_tokenizer_class \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mtokenizer_class\n\u001B[1;32m    868\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto_map\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAutoTokenizer\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config\u001B[38;5;241m.\u001B[39mauto_map:\n",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:1006\u001B[0m, in \u001B[0;36mAutoConfig.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[1;32m   1003\u001B[0m trust_remote_code \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrust_remote_code\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m   1004\u001B[0m code_revision \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode_revision\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m-> 1006\u001B[0m config_dict, unused_kwargs \u001B[38;5;241m=\u001B[39m PretrainedConfig\u001B[38;5;241m.\u001B[39mget_config_dict(pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1007\u001B[0m has_remote_code \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto_map\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAutoConfig\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto_map\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1008\u001B[0m has_local_code \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict \u001B[38;5;129;01mand\u001B[39;00m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m CONFIG_MAPPING\n",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/transformers/configuration_utils.py:570\u001B[0m, in \u001B[0;36mPretrainedConfig.get_config_dict\u001B[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[1;32m    568\u001B[0m original_kwargs \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(kwargs)\n\u001B[1;32m    569\u001B[0m \u001B[38;5;66;03m# Get config dict associated with the base config file\u001B[39;00m\n\u001B[0;32m--> 570\u001B[0m config_dict, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_get_config_dict(pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {}, kwargs\n",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/transformers/configuration_utils.py:629\u001B[0m, in \u001B[0;36mPretrainedConfig._get_config_dict\u001B[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[1;32m    625\u001B[0m configuration_file \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_configuration_file\u001B[39m\u001B[38;5;124m\"\u001B[39m, CONFIG_NAME) \u001B[38;5;28;01mif\u001B[39;00m gguf_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m gguf_file\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001B[39;00m\n\u001B[0;32m--> 629\u001B[0m     resolved_config_file \u001B[38;5;241m=\u001B[39m cached_file(\n\u001B[1;32m    630\u001B[0m         pretrained_model_name_or_path,\n\u001B[1;32m    631\u001B[0m         configuration_file,\n\u001B[1;32m    632\u001B[0m         cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n\u001B[1;32m    633\u001B[0m         force_download\u001B[38;5;241m=\u001B[39mforce_download,\n\u001B[1;32m    634\u001B[0m         proxies\u001B[38;5;241m=\u001B[39mproxies,\n\u001B[1;32m    635\u001B[0m         resume_download\u001B[38;5;241m=\u001B[39mresume_download,\n\u001B[1;32m    636\u001B[0m         local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[1;32m    637\u001B[0m         token\u001B[38;5;241m=\u001B[39mtoken,\n\u001B[1;32m    638\u001B[0m         user_agent\u001B[38;5;241m=\u001B[39muser_agent,\n\u001B[1;32m    639\u001B[0m         revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[1;32m    640\u001B[0m         subfolder\u001B[38;5;241m=\u001B[39msubfolder,\n\u001B[1;32m    641\u001B[0m         _commit_hash\u001B[38;5;241m=\u001B[39mcommit_hash,\n\u001B[1;32m    642\u001B[0m     )\n\u001B[1;32m    643\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m resolved_config_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    644\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, kwargs\n",
      "File \u001B[0;32m~/anaconda3/envs/AINotebook/lib/python3.12/site-packages/transformers/utils/hub.py:446\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[1;32m    440\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    441\u001B[0m         resolved_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    442\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _raise_exceptions_for_missing_entries\n\u001B[1;32m    443\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _raise_exceptions_for_connection_errors\n\u001B[1;32m    444\u001B[0m     ):\n\u001B[1;32m    445\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m resolved_file\n\u001B[0;32m--> 446\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m    447\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWe couldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt connect to \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m to load this file, couldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find it in the\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    448\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m cached files and it looks like \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not the path to a directory containing a file named\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    449\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfull_filename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mCheckout your internet connection or see how to run the library in offline mode at\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    450\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    451\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m EntryNotFoundError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _raise_exceptions_for_missing_entries:\n",
      "\u001B[0;31mOSError\u001B[0m: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like meta-llama/Meta-Llama-3.1-8B is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "1adcf323-de9d-4c24-a9c3-d7ae554d06ca",
   "metadata": {},
   "source": [
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "049885d4-fdfa-4ff0-a932-4a2ed73928e2",
   "metadata": {},
   "source": [
    "# Load in our dataset\n",
    "\n",
    "dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", f\"raw_meta_Appliances\", split=\"full\", trust_remote_code=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cde08860-b393-49b8-a620-06a8c0990a64",
   "metadata": {},
   "source": [
    "print(f\"Number of Appliances: {len(dataset):,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3e29a5ab-ca61-41cc-9b33-22d374681b85",
   "metadata": {},
   "source": [
    "# Investigate a particular datapoint\n",
    "datapoint = dataset[2]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "40a4e10f-6710-4780-a95e-6c0030c3fb87",
   "metadata": {},
   "source": [
    "# Investigate\n",
    "\n",
    "print(datapoint[\"title\"])\n",
    "print(datapoint[\"description\"])\n",
    "print(datapoint[\"features\"])\n",
    "print(datapoint[\"details\"])\n",
    "print(datapoint[\"price\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9d356c6f-b6e8-4e01-98cd-c562d132aafa",
   "metadata": {},
   "source": [
    "# How many have prices?\n",
    "\n",
    "prices = 0\n",
    "for datapoint in dataset:\n",
    "    try:\n",
    "        price = float(datapoint[\"price\"])\n",
    "        if price > 0:\n",
    "            prices += 1\n",
    "    except ValueError as e:\n",
    "        pass\n",
    "\n",
    "print(f\"There are {prices:,} with prices which is {prices/len(dataset)*100:,.1f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bd890259-aa25-4097-9524-f91c2bdd719b",
   "metadata": {},
   "source": [
    "# For those with prices, gather the price and the length\n",
    "\n",
    "prices = []\n",
    "lengths = []\n",
    "for datapoint in dataset:\n",
    "    try:\n",
    "        price = float(datapoint[\"price\"])\n",
    "        if price > 0:\n",
    "            prices.append(price)\n",
    "            contents = datapoint[\"title\"] + str(datapoint[\"description\"]) + str(datapoint[\"features\"]) + str(datapoint[\"details\"])\n",
    "            lengths.append(len(contents))\n",
    "    except ValueError as e:\n",
    "        pass"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "89078cb1-9679-4eb0-b295-599b8586bcd1",
   "metadata": {},
   "source": [
    "# Plot the distribution of lengths\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Lengths: Avg {sum(lengths)/len(lengths):,.0f} and highest {max(lengths):,}\\n\")\n",
    "plt.xlabel('Length (chars)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(lengths, rwidth=0.7, color=\"lightblue\", bins=range(0, 6000, 100))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c38e0c43-9f7a-450e-a911-c94d37d9b9c3",
   "metadata": {},
   "source": [
    "# Plot the distribution of prices\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Prices: Avg {sum(prices)/len(prices):,.2f} and highest {max(prices):,}\\n\")\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(prices, rwidth=0.7, color=\"orange\", bins=range(0, 1000, 10))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eabc7c61-0cd2-41f4-baa1-b85400bbf87f",
   "metadata": {},
   "source": [
    "# So what is this item??\n",
    "\n",
    "for datapoint in dataset:\n",
    "    try:\n",
    "        price = float(datapoint[\"price\"])\n",
    "        if price > 21000:\n",
    "            print(datapoint['title'])\n",
    "    except ValueError as e:\n",
    "        pass"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3668ae25-3461-4e6e-9ccb-221c1925a497",
   "metadata": {},
   "source": [
    "This is the closest I can find - looks like it's going at a bargain price!!\n",
    "\n",
    "https://www.amazon.com/TurboChef-Electric-Countertop-Microwave-Convection/dp/B01D05U9NO/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d02f58-23f6-4f81-a779-7c0555afd13d",
   "metadata": {},
   "source": [
    "## Now it's time to curate our dataset\n",
    "\n",
    "We select items that cost between 1 and 999 USD\n",
    "\n",
    "We will be create Item instances, which truncate the text to fit within 180 tokens using the right Tokenizer\n",
    "\n",
    "And will create a prompt to be used during Training.\n",
    "\n",
    "Items will be rejected if they don't have sufficient characters.\n",
    "\n",
    "## But why 180 tokens??\n",
    "\n",
    "A student asked me a great question - why are we truncating to 180 tokens? How did we determine that number? (Thank you Moataz A. for the excellent question).\n",
    "\n",
    "The answer: this is an example of a \"hyper-parameter\". In other words, it's basically trial and error! We want a sufficiently large number of tokens so that we have enough useful information to gauge the price. But we also want to keep the number low so that we can train efficiently. You'll see this in action in Week 7.\n",
    "\n",
    "I started with a number that seemed reasonable, and experimented with a few variations before settling on 180. If you have time, you should do the same! You might find that you can beat my results by finding a better balance. This kind of trial-and-error might sound a bit unsatisfactory, but it's a crucial part of the data science R&D process.\n",
    "\n",
    "There's another interesting reason why we might favor a lower number of tokens in the training data. When we eventually get to use our model at inference time, we'll want to provide new products and have it estimate a price. And we'll be using short descriptions of products - like 1-2 sentences. For best performance, we should size our training data to be similar to the inputs we will provide at inference time.\n",
    "\n",
    "## But I see in items.py it constrains inputs to 160 tokens?\n",
    "\n",
    "Another great question from Moataz A.! The description of the products is limited to 160 tokens because we add some more text before and after the description to turn it into a prompt. That brings it to around 180 tokens in total.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "430b432f-b769-41da-9506-a238cb5cf1b6",
   "metadata": {},
   "source": [
    "# Create an Item object for each with a price\n",
    "\n",
    "items = []\n",
    "for datapoint in dataset:\n",
    "    try:\n",
    "        price = float(datapoint[\"price\"])\n",
    "        if price > 0:\n",
    "            item = Item(datapoint, price)\n",
    "            if item.include:\n",
    "                items.append(item)\n",
    "    except ValueError as e:\n",
    "        pass\n",
    "\n",
    "print(f\"There are {len(items):,} items\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0d570794-6f1d-462e-b567-a46bae3556a1",
   "metadata": {},
   "source": [
    "# Look at the first item\n",
    "\n",
    "items[1]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70219e99-22cc-4e08-9121-51f9707caef0",
   "metadata": {},
   "source": [
    "# Investigate the prompt that will be used during training - the model learns to complete this\n",
    "\n",
    "print(items[100].prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d9998b8d-d746-4541-9ac2-701108e0e8fb",
   "metadata": {},
   "source": [
    "# Investigate the prompt that will be used during testing - the model has to complete this\n",
    "\n",
    "print(items[100].test_prompt())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7a116369-335a-412b-b70c-2add6675c2e3",
   "metadata": {},
   "source": [
    "# Plot the distribution of token counts\n",
    "\n",
    "tokens = [item.token_count for item in items]\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Token counts: Avg {sum(tokens)/len(tokens):,.1f} and highest {max(tokens):,}\\n\")\n",
    "plt.xlabel('Length (tokens)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(tokens, rwidth=0.7, color=\"green\", bins=range(0, 300, 10))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d1744aa-71e7-435e-876e-91f06583211a",
   "metadata": {},
   "source": [
    "# Plot the distribution of prices\n",
    "\n",
    "prices = [item.price for item in items]\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Prices: Avg {sum(prices)/len(prices):,.1f} and highest {max(prices):,}\\n\")\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(prices, rwidth=0.7, color=\"purple\", bins=range(0, 300, 10))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2b58dc61-747f-46f7-b9e0-c205db4f3e5e",
   "metadata": {},
   "source": [
    "## Sidenote\n",
    "\n",
    "If you like the variety of colors that matplotlib can use in its charts, you should bookmark this:\n",
    "\n",
    "https://matplotlib.org/stable/gallery/color/named_colors.html\n",
    "\n",
    "## Todos for you:\n",
    "\n",
    "- Review the Item class and check you're comfortable with it\n",
    "- Examine some Item objects, look at the training prompt with `item.prompt` and test prompt with `item.test_prompt()`\n",
    "- Make some more histograms to better understand the data\n",
    "\n",
    "## Next time we will combine with many other types of product\n",
    "\n",
    "Like Electronics and Automotive. This will give us a massive dataset, and we can then be picky about choosing a subset that will be most suitable for training."
   ]
  },
  {
   "cell_type": "code",
   "id": "01401283-d111-40a7-96e5-0ca05bb20857",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
